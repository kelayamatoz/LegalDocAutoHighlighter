
Legal documents are known for being lengthy. To our knowledge, some
categories of legal documents contain duplicated information that do
not need attention. However, manually extracting useful information
from documents requires a considerate amount of effort. In this
project, we propose a set of algorithms that finds duplicate parts
within a set of legal documents and returns useful information
regarding the differences to the user.  More ambitiously, if possible,
we wish to train a learner on a large dataset of legal documents (e.g.
software user agreements, liability waivers, etc.), so that this
learner could automatically mark salient or unordinary parts of a new
legal document for manual scrutinization.



I. Input and Output Behaviors

We want to use a set of legal documents as the input. To start off, we
will use software user agreements (e.g. Apple user agreements). Using
software user agreements have several benefits:

It is easy to acquire digital version of software user agreements.
Only very few people would bother reading the lengthy user agreements
(in fact, neither of us has ever tried finishing reading the 40ish
page apple product user agreement), which indicates that a lot of
information in these user agreements might be useless.

The output of the system will be several clusters that partition legal
documents into paragraphs with similar meanings. Parts that are
uncommon or noteworthy for further inspection will be highlighted for
the users to pay special attention to.


II.   Scope of the Project

We might wish to restrict the scope of this project to only software
user agreements and similar documents with less legal risks for the
sake of feasibility. But we can also apply similar approaches to other
legal documents like NDAs, work contracts, renting contracts and so
forth. Processing these documents has more pragmatic value, and as
long as our algorithm only provides consultative guidance for the
actual signer, we don’t need to worry too much about our own legal
risks.



III.   Evaluation Metric

Currently we couldn’t conceive a repeatable evaluation metric for
success. It is hard to judge the accuracy of extracting salient
components from a document using mechanical methods. A lot of judging
process will happen by subjective interpretation. 

However, we would be able to manually produce some legal documents
with abnormal clauses inserted. If we test these cooked documents
against our algorithm, we should be able to give a fairly quantitative
understanding of its performance by evaluating the percentage of
abnormalities it has highlighted.


IV.     Challenges and Solutions

Feature extraction. How are we going to extract information from each document?

Clustering. After extraction, how are we going to categorize different
parts of the documents into useful / useless? Or shall we take on a
regression approach to give a significance score to document
components (sentences, even words)?

Measuring. How should we measure the difference between documents by
some algorithms? And how refined the comparison should be?

With our current knowledge, we suggest that the following high-level
methods might be appropriate to address these challenges: sentiment
analysis, logistic regression, K-means clustering, PCA, SVM, LDA.
We might also need some tools in natural language
processing and statistical modeling.
